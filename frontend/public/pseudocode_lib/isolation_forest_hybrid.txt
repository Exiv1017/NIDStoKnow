




EXTRACT_FEATURES(cmd):
  - features := [L=len(cmd), arg_count, special_chars, path_seps, digit_ratio, entropy, uppercase_ratio, suspicious_flag]
  - return (names, numeric_vector)

TRAIN_OR_LOAD():
  - load persisted model+meta if present, else:
    - rows := fetch_training_commands() or [""]
    - X := map(EXTRACT_FEATURES, rows)
    - defaults: contamination=0.10, n_trees=100, max_samples=min(256, |X|)
    - fit IsolationForest(random_state=42) on X
    - meta.min_df, meta.max_df := min/max(decision_function(X))
    - persist(model, meta)
  - return (model, meta)

NORMALIZE_INVERT(df, min_df, max_df):
  - score := clamp((max_df - df) / max(1e-12, max_df - min_df), 0, 1)
  - return score

COMPUTE_SEMANTIC_BOOST(cmd, patterns):
  - total := sum(p.boost_value for p in patterns if regex_match(p.regex, cmd))
  - return (min(0.25, 0.02 * total), matched_patterns)

SCORE_COMMAND(cmd):
  - (model, meta) := TRAIN_OR_LOAD()
  - vec := EXTRACT_FEATURES(cmd).vector
  - base := NORMALIZE_INVERT(decision_function(model, vec), meta.min_df, meta.max_df)
  - boost, matches := COMPUTE_SEMANTIC_BOOST(cmd, fetch_active_boost_patterns())
  - boosted := min(1.0, base + boost)
  - label := ANOMALY if boosted >= (meta.config.threshold or 0.70) else NORMAL
  - return {label, base, boosted, threshold, matches, features: vec, model_version: meta.version}

HYBRID_DETECT(cmd):
  - sigs := match_signatures(cmd)  // Ahoâ€“Corasick + regex
  - anomaly := SCORE_COMMAND(cmd)
  - severity := HIGH if sigs not empty or anomaly.label==ANOMALY else LOW/ MEDIUM (ANOMALY->MEDIUM otherwise LOW)
  - return {cmd, signatures: sigs, anomaly, severity}

Notes: keep boost small (<=0.25), persist meta.min_df/max_df and feature order to ensure stable normalization.


